{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8375811,"sourceType":"datasetVersion","datasetId":4980137}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Incremental learning part 2\n\n\n*** In this notebook we train previously trained model, supposedly trained in `Incremental learning part 1.` notebook.***","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport shutil\nimport numpy as np\nimport tensorflow as tf\nimport plotly.graph_objs as go\nfrom tensorflow.keras.layers import Dense\n\nfrom keras.models import load_model\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.applications import MobileNetV2, MobileNet, MobileNetV3Small, EfficientNetB0, EfficientNetB1, EfficientNetB3, EfficientNetB4, EfficientNetB7\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nfrom keras.callbacks import ModelCheckpoint\nfrom sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, roc_curve, auc\n\nimport plotly.io as pio","metadata":{"id":"BTvqUlqRnpXr","execution":{"iopub.status.busy":"2024-05-09T12:59:03.887134Z","iopub.execute_input":"2024-05-09T12:59:03.887396Z","iopub.status.idle":"2024-05-09T12:59:15.986321Z","shell.execute_reply.started":"2024-05-09T12:59:03.887372Z","shell.execute_reply":"2024-05-09T12:59:15.985504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Setup pipeline veriables","metadata":{"id":"UwzVnTfMrV3e","execution":{"iopub.status.busy":"2024-03-06T13:21:29.243655Z","iopub.execute_input":"2024-03-06T13:21:29.244264Z","iopub.status.idle":"2024-03-06T13:21:29.250988Z","shell.execute_reply.started":"2024-03-06T13:21:29.244231Z","shell.execute_reply":"2024-03-06T13:21:29.249871Z"}}},{"cell_type":"code","source":"SEED = 20\nDRIVE_PATH = \"/kaggle\"\nDATA_DIRECTORY = f\"{DRIVE_PATH}/input/sneakers-recognition-dataset-v22/Sneakers_Recognition_DataSet\"\nSHOW_DATASET_STRUCTURE = False\nSHOW_IMAGE_SHAPE_MEANS = False\nShOW_IMAGE_SHAPE_PLOT = False\nDRAW_CLASS_DISTRIBUTION = False\n\n# IMAGE_SIZE = (300, 300)\n\n# IMAGE_SIZE = (244, 244)\n\n# IMAGE_SIZE = (224, 224)\n\n\nIMAGE_SIZE = (240, 240)\nBATCH_SIZE = 32\nEPOCHS = 15\nNUMBER_LAYERS_TO_FREEZE = 0\nMODEL_CLASS_CALLBACK = EfficientNetB1\nSHOW_NUMBER_OF_LAYERS_IN_BASE_MODEL = True\nSHOW_MODEL_SUMMARY = False\n\nNUMBER_OF_CLASSES_OF_FIRST_MODEL = 30\nNUMBER_OF_CLASSES_TO_TRAIN_MODEL_ON = 33\n\n# LOAD_MODEL_NAME = f\"IncrementalLearningPart1_{NUMBER_OF_CLASSES_OF_FIRST_MODEL}Classes_DATA_V2_{MODEL_CLASS_CALLBACK}_{NUMBER_LAYERS_TO_FREEZE}Frozen_{BATCH_SIZE}Batch_{IMAGE_SIZE[0]}x{IMAGE_SIZE[1]}Size_AugV2\"\n# LOAD_MODEL_DIR_PATH = f\"/kaggle/input/incremental_models_efficientnetb1/tensorflow2/incremental_learning_part1_{NUMBER_OF_CLASSES_OF_FIRST_MODEL}classes/1/\"\n# LOAD_MODEL_PATH = f\"{LOAD_MODEL_DIR_PATH}{LOAD_MODEL_NAME}.keras\"\n\nLOAD_MODEL_PATH = \"/kaggle/input/efficientnetb1_30classes/tensorflow2/incremental_learning_part1/1/model.h5\"\n\n# Define the destination path where you want to copy the model\nLOAD_MODEL_PATH_TO_USE = \"/kaggle/working/copied_model.h5\"\n\n\nMODEL_SAVING_PATH = f\"{DRIVE_PATH}/working/models/IncrementalLearningPart2_{NUMBER_OF_CLASSES_TO_TRAIN_MODEL_ON}Classes_DATA_V2_{MODEL_CLASS_CALLBACK}_{NUMBER_LAYERS_TO_FREEZE}Frozen_{BATCH_SIZE}Batch_{IMAGE_SIZE[0]}x{IMAGE_SIZE[1]}Size_AugV2\"","metadata":{"execution":{"iopub.status.busy":"2024-05-09T12:59:15.987855Z","iopub.execute_input":"2024-05-09T12:59:15.988355Z","iopub.status.idle":"2024-05-09T12:59:15.995315Z","shell.execute_reply.started":"2024-05-09T12:59:15.988328Z","shell.execute_reply":"2024-05-09T12:59:15.994302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def list_directories(root_dir):\n    \"\"\"\n    Recursively lists all directories and subdirectories within the specified directory.\n\n    Args:\n    - root_dir (str): The directory to list.\n\n    Returns:\n    - directories (list): A list of directory paths.\n    \"\"\"\n    directories = []\n    for dirpath, dirnames, filenames in os.walk(root_dir):\n        directories.append(dirpath)\n        for dirname in dirnames:\n            directories.append(os.path.join(dirpath, dirname))\n    return directories\n\n\nif SHOW_DATASET_STRUCTURE:\n    directories_structure = list_directories(DATA_DIRECTORY)\n    for directory in directories_structure:\n        print(directory)\n","metadata":{"id":"P5iOB85MiSHc","execution":{"iopub.status.busy":"2024-05-09T12:59:15.996595Z","iopub.execute_input":"2024-05-09T12:59:15.996913Z","iopub.status.idle":"2024-05-09T12:59:16.019208Z","shell.execute_reply.started":"2024-05-09T12:59:15.996883Z","shell.execute_reply":"2024-05-09T12:59:16.018462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dirs_arr = list_directories(DATA_DIRECTORY)\n\n\nall_classes = [path.split('/')[-1] for path in dirs_arr[1:]]\nall_classes_sorted = sorted(list(set(all_classes)))\nclasses_for_datagen = all_classes_sorted[:NUMBER_OF_CLASSES_TO_TRAIN_MODEL_ON]\nclasses_for_datagen[:3], len(classes_for_datagen)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T12:59:16.021454Z","iopub.execute_input":"2024-05-09T12:59:16.021777Z","iopub.status.idle":"2024-05-09T12:59:17.522179Z","shell.execute_reply.started":"2024-05-09T12:59:16.021753Z","shell.execute_reply":"2024-05-09T12:59:17.521256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to calculate mean dimensions of images in a directory\ndef calculate_mean_dimensions(directory):\n    total_width = 0\n    total_height = 0\n    total_images = 0\n\n    # Iterate through files in the directory\n    for filename in os.listdir(directory):\n        if filename.endswith(\".jpg\") or filename.endswith(\".png\"): # Add other formats if needed\n            img_path = os.path.join(directory, filename)\n            img = cv2.imread(img_path)\n            if img is not None:\n                total_width += img.shape[1]\n                total_height += img.shape[0]\n                total_images += 1\n\n    # Calculate mean dimensions\n    if total_images > 0:\n        mean_width = total_width / total_images\n        mean_height = total_height / total_images\n        return mean_width, mean_height\n    else:\n        return 0, 0\n\nif SHOW_IMAGE_SHAPE_MEANS:\n    # Iterate through subdirectories\n    for subdir in os.listdir(DATA_DIRECTORY):\n        subdir_path = os.path.join(DATA_DIRECTORY, subdir)\n        if os.path.isdir(subdir_path):\n            mean_width, mean_height = calculate_mean_dimensions(subdir_path)\n            print(f\"Directory: {subdir}, Mean Width: {mean_width}, Mean Height: {mean_height}\")\n","metadata":{"id":"zoJ-mrYM9sLN","execution":{"iopub.status.busy":"2024-05-09T12:59:17.523358Z","iopub.execute_input":"2024-05-09T12:59:17.523762Z","iopub.status.idle":"2024-05-09T12:59:17.532831Z","shell.execute_reply.started":"2024-05-09T12:59:17.523726Z","shell.execute_reply":"2024-05-09T12:59:17.531903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def collect_dimensions(directory):\n    widths = []\n    heights = []\n\n    # Iterate through files in the directory\n    for root, _, files in os.walk(directory):\n        print(f\"Gathering data from {root} directory\")\n        for filename in files:\n            if filename.endswith(\".jpg\") or filename.endswith(\".png\"): # Add other formats if needed\n                img_path = os.path.join(root, filename)\n                img = cv2.imread(img_path)\n                if img is not None:\n                    widths.append(img.shape[1])\n                    heights.append(img.shape[0])\n\n    return widths, heights\n\ndef plot_dimension_distribution(widths, heights):\n    # Create histograms\n    width_hist = go.Histogram(x=widths, name='Width', marker_color='blue')\n    height_hist = go.Histogram(x=heights, name='Height', marker_color='green')\n\n    # Create figure\n    fig = go.Figure(data=[width_hist, height_hist])\n\n    # Update layout\n    fig.update_layout(\n        title='Image Dimension Distribution',\n        xaxis=dict(title='Dimension'),\n        yaxis=dict(title='Frequency'),\n        barmode='overlay',\n        bargap=0.1\n    )\n\n    # Show plot\n    fig.show()\n\ndef visualize_distribution(directory):\n    widths, heights = collect_dimensions(directory)\n    plot_dimension_distribution(widths, heights)\n\n\nif ShOW_IMAGE_SHAPE_PLOT:\n  # Visualize distribution\n  visualize_distribution(DATA_DIRECTORY)\n","metadata":{"id":"XukpOdIfGcHu","execution":{"iopub.status.busy":"2024-05-09T12:59:17.533971Z","iopub.execute_input":"2024-05-09T12:59:17.534234Z","iopub.status.idle":"2024-05-09T12:59:17.547653Z","shell.execute_reply.started":"2024-05-09T12:59:17.534211Z","shell.execute_reply":"2024-05-09T12:59:17.546780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create train and validation data generators\ntrain_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.2,\n    rotation_range = 30,\n    shear_range = 0.2,\n    height_shift_range = 0.2,\n    width_shift_range = 0.2,\n    brightness_range = (0.2, 1.0),\n    zoom_range = 0.2,\n    horizontal_flip = True,\n    fill_mode = 'nearest'\n)\n\n# Create train data generator\ntrain_generator = train_datagen.flow_from_directory(\n    DATA_DIRECTORY,\n    target_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='training',  # specify this as training data\n    seed=SEED,\n#     classes={v: i for i, v in enumerate(classes_for_datagen)}\n#     classes={\"Adidas_10050\": 1}\n    classes=classes_for_datagen  # specify the desired classes\n)\n\n# Create validation data generator\nvalidation_generator = train_datagen.flow_from_directory(\n    DATA_DIRECTORY,\n    target_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='validation',  # specify this as validation data\n    seed=SEED,\n    classes=classes_for_datagen  # specify the desired classes\n)\n\n# The number of labels will be the length of the desired classes list\nnumber_of_labels = len(classes_for_datagen)","metadata":{"id":"qllRXxP9i0Lk","outputId":"2b7d44b4-11d1-4de8-f6d9-562d1061edf2","execution":{"iopub.status.busy":"2024-05-09T12:59:17.548661Z","iopub.execute_input":"2024-05-09T12:59:17.548922Z","iopub.status.idle":"2024-05-09T12:59:17.752282Z","shell.execute_reply.started":"2024-05-09T12:59:17.548900Z","shell.execute_reply":"2024-05-09T12:59:17.751619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the number of classes in the train generator\ntrain_class_indices = train_generator.class_indices\ntrain_num_classes = len(train_class_indices)\nprint(\"Number of classes in train generator:\", train_num_classes)\n\n# Check the number of classes in the validation generator\nvalidation_class_indices = validation_generator.class_indices\nvalidation_num_classes = len(validation_class_indices)\nprint(\"Number of classes in validation generator:\", validation_num_classes)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T12:59:17.753410Z","iopub.execute_input":"2024-05-09T12:59:17.753684Z","iopub.status.idle":"2024-05-09T12:59:17.758763Z","shell.execute_reply.started":"2024-05-09T12:59:17.753662Z","shell.execute_reply":"2024-05-09T12:59:17.757848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_generator.class_indices, train_generator.class_indices","metadata":{"execution":{"iopub.status.busy":"2024-05-09T12:59:17.759910Z","iopub.execute_input":"2024-05-09T12:59:17.760543Z","iopub.status.idle":"2024-05-09T12:59:17.773214Z","shell.execute_reply.started":"2024-05-09T12:59:17.760519Z","shell.execute_reply":"2024-05-09T12:59:17.772170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(validation_generator.class_indices.keys())","metadata":{"execution":{"iopub.status.busy":"2024-05-09T12:59:17.776622Z","iopub.execute_input":"2024-05-09T12:59:17.776958Z","iopub.status.idle":"2024-05-09T12:59:17.784006Z","shell.execute_reply.started":"2024-05-09T12:59:17.776929Z","shell.execute_reply":"2024-05-09T12:59:17.783184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def draw_class_distribution_bar_plot(class_distribution, save_path):\n    sorted_class_distribution = dict(sorted(class_distribution.items()))\n    fig = go.Figure(data=[go.Bar(x=list(sorted_class_distribution.keys()), y=list(sorted_class_distribution.values()))])\n    fig.update_layout(title='Class Distribution',\n                      xaxis_title='Class',\n                      yaxis_title='Count',\n                      width=1000,\n                      height=600)\n    fig.write_html(save_path)  # Save the plot to the specified path as HTML\n    fig.show()\n\n# Example usage of drawing class distribution bar plot\ndef draw_class_distribution(generator, save_path):\n    class_indices_mapping = generator.class_indices\n\n    # Reverse the mapping to get class names from indices\n    class_names = {v: k for k, v in class_indices_mapping.items()}\n    \n    class_distribution = {}\n    for label in generator.labels:\n        if label in class_distribution:\n            class_distribution[label] += 1\n        else:\n            class_distribution[label] = 1\n\n    draw_class_distribution_bar_plot(class_distribution, save_path)\n    \n\nif DRAW_CLASS_DISTRIBUTION:\n    draw_class_distribution(train_generator, os.path.join(f\"{DRIVE_PATH}/working\", \"class_distribution_train.html\"))\n    draw_class_distribution(validation_generator, os.path.join(f\"{DRIVE_PATH}/working\", \"class_distribution_validation.html\"))","metadata":{"execution":{"iopub.status.busy":"2024-05-09T12:59:17.784994Z","iopub.execute_input":"2024-05-09T12:59:17.785262Z","iopub.status.idle":"2024-05-09T12:59:17.795923Z","shell.execute_reply.started":"2024-05-09T12:59:17.785239Z","shell.execute_reply":"2024-05-09T12:59:17.795151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Copy the model to the destination\nshutil.copy(LOAD_MODEL_PATH, LOAD_MODEL_PATH_TO_USE)\n\n# Load the model from the destination path\nmodel = tf.keras.models.load_model(LOAD_MODEL_PATH_TO_USE)\n\n# Add a new output layer with the desired number of neurons and softmax activation\nnew_output_layer = Dense(NUMBER_OF_CLASSES_TO_TRAIN_MODEL_ON, activation='softmax')\n\n# Add the new output layer to the model\nmodel = Model(inputs=model.input, outputs=new_output_layer(model.layers[-2].output))\n\n# Compile the model with an appropriate loss function, optimizer, and metrics\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T12:59:17.796885Z","iopub.execute_input":"2024-05-09T12:59:17.797139Z","iopub.status.idle":"2024-05-09T12:59:21.941082Z","shell.execute_reply.started":"2024-05-09T12:59:17.797117Z","shell.execute_reply":"2024-05-09T12:59:21.940228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if SHOW_MODEL_SUMMARY:\n    model.summary()","metadata":{"id":"2B9Av6KBvehm","outputId":"e5917b6a-3fb3-4e4c-e3b1-c14a1bee2a33","execution":{"iopub.status.busy":"2024-05-09T12:59:21.942285Z","iopub.execute_input":"2024-05-09T12:59:21.942611Z","iopub.status.idle":"2024-05-09T12:59:21.946960Z","shell.execute_reply.started":"2024-05-09T12:59:21.942575Z","shell.execute_reply":"2024-05-09T12:59:21.945946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import LearningRateScheduler\n\n# Define the learning rate schedule function\ndef lr_schedule(epoch):\n    initial_lr = 0.001\n    if epoch is set([15, 25]):\n        return initial_lr * 0.1\n    return initial_lr\n\n# Define the LearningRateScheduler callback\nlr_scheduler = LearningRateScheduler(lr_schedule)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T12:59:21.948193Z","iopub.execute_input":"2024-05-09T12:59:21.948617Z","iopub.status.idle":"2024-05-09T12:59:22.015019Z","shell.execute_reply.started":"2024-05-09T12:59:21.948586Z","shell.execute_reply":"2024-05-09T12:59:22.014145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ensure the directory exists\nos.makedirs(MODEL_SAVING_PATH, exist_ok=True)\n\n# Define a callback to save the model weights after every epoch\ncheckpoint_filepath = MODEL_SAVING_PATH + \"/model_weights_epoch_{epoch:02d}.weights.h5\"\nmodel_checkpoint_callback = ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    monitor='val_accuracy',\n    mode='max',\n    save_best_only=False,\n    verbose=1\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T12:59:22.016206Z","iopub.execute_input":"2024-05-09T12:59:22.016878Z","iopub.status.idle":"2024-05-09T12:59:22.024889Z","shell.execute_reply.started":"2024-05-09T12:59:22.016851Z","shell.execute_reply":"2024-05-09T12:59:22.023977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train our model","metadata":{}},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(\n    train_generator,\n    validation_data=validation_generator,\n    epochs=EPOCHS,\n    callbacks=[model_checkpoint_callback, lr_scheduler]\n)","metadata":{"id":"MJYKFVTOjXQ-","outputId":"cad35a00-161e-4ab9-b7ca-02579bd59694","execution":{"iopub.status.busy":"2024-05-09T12:59:22.025946Z","iopub.execute_input":"2024-05-09T12:59:22.028181Z","iopub.status.idle":"2024-05-09T13:36:44.026894Z","shell.execute_reply.started":"2024-05-09T12:59:22.028150Z","shell.execute_reply":"2024-05-09T13:36:44.025949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Save the trained model\n# model.save(f\"{MODEL_SAVING_PATH}/model.h5\")","metadata":{"id":"p4wYg_srWb4p","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get training and validation loss values\ntrain_loss = history.history['loss']\nval_loss = history.history['val_loss']\n\n# Get training and validation accuracy values\ntrain_acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\n# Create traces for loss\nloss_trace = go.Scatter(x=list(range(1, len(train_loss) + 1)), y=train_loss, mode='lines', name='Training Loss')\nval_loss_trace = go.Scatter(x=list(range(1, len(val_loss) + 1)), y=val_loss, mode='lines', name='Validation Loss')\n\n# Create traces for accuracy\nacc_trace = go.Scatter(x=list(range(1, len(train_acc) + 1)), y=train_acc, mode='lines', name='Training Accuracy')\nval_acc_trace = go.Scatter(x=list(range(1, len(val_acc) + 1)), y=val_acc, mode='lines', name='Validation Accuracy')\n\n# Create figure for loss\nloss_fig = go.Figure(data=[loss_trace, val_loss_trace])\nloss_fig.update_layout(title='Training and Validation Loss',\n                       xaxis_title='Epoch',\n                       yaxis_title='Loss')\n\n# Create figure for accuracy\nacc_fig = go.Figure(data=[acc_trace, val_acc_trace])\nacc_fig.update_layout(title='Training and Validation Accuracy',\n                      xaxis_title='Epoch',\n                      yaxis_title='Accuracy')\n\n# Save figures as HTML files\npio.write_html(loss_fig, f\"{MODEL_SAVING_PATH}/loss_figure.html\")\npio.write_html(acc_fig, f\"{MODEL_SAVING_PATH}/accuracy_figure.html\")\n","metadata":{"id":"yNehpeTczZsl","execution":{"iopub.status.busy":"2024-05-09T13:45:15.906656Z","iopub.execute_input":"2024-05-09T13:45:15.907030Z","iopub.status.idle":"2024-05-09T13:45:16.187579Z","shell.execute_reply.started":"2024-05-09T13:45:15.907002Z","shell.execute_reply":"2024-05-09T13:45:16.186623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_true_and_predicted(generator, model):\n    # Get true labels and predicted labels\n    true_labels = []\n    predicted_labels = []\n    predicted_probabilities = []\n    for i in range(len(generator)):\n        batch = generator[i]\n        true_labels.extend(np.argmax(batch[1], axis=1))  # Extract true labels from the batch\n        predictions = model.predict(batch[0])\n        predicted_labels.extend(np.argmax(predictions, axis=1))  # Extract predicted labels\n        predicted_probabilities.extend(predictions)  # Extract predicted probabilities\n    return true_labels, predicted_labels, predicted_probabilities","metadata":{"execution":{"iopub.status.busy":"2024-05-09T13:45:16.902591Z","iopub.execute_input":"2024-05-09T13:45:16.903418Z","iopub.status.idle":"2024-05-09T13:45:16.909334Z","shell.execute_reply.started":"2024-05-09T13:45:16.903387Z","shell.execute_reply":"2024-05-09T13:45:16.908424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Function to plot confusion matrix using Plotly\ndef plot_confusion_matrix(conf_matrix, class_names, title, save_path=None):\n    trace = go.Heatmap(z=np.flipud(conf_matrix),  # Reverse the y-axis\n                       x=class_names,\n                       y=class_names[::-1],  # Reverse the y-axis labels\n                       colorscale='Blues',\n                       colorbar=dict(title='Count'),\n                       )\n    layout = go.Layout(title=title,\n                       xaxis=dict(title='Predicted labels'),\n                       yaxis=dict(title='True labels'),\n                       width=1000,  # Specify width of the plot\n                       height=1000,  # Specify height of the plot\n#                        legend=dict(title='Legend'),  # Include legend\n                       )\n    fig = go.Figure(data=[trace], layout=layout)\n    if save_path:\n        fig.write_html(save_path)  # Save the plot to the specified path as HTML\n    fig.show()\n\n# Function to calculate metrics and plot ROC-AUC curve\ndef calculate_metrics_and_plot_roc(true_labels, predicted_probabilities, class_names, title, save_path=None):\n    # Calculate accuracy\n    accuracy = accuracy_score(true_labels, predicted_probabilities.argmax(axis=1))\n\n    # Calculate top-5 accuracy\n    top5_accuracy = top_k_accuracy(true_labels, predicted_probabilities, k=5)\n\n    # Calculate F1 score\n    f1 = f1_score(true_labels, predicted_probabilities.argmax(axis=1), average='macro')\n\n    # Calculate precision\n    precision = precision_score(true_labels, predicted_probabilities.argmax(axis=1), average='macro')\n\n    # Calculate recall\n    recall = recall_score(true_labels, predicted_probabilities.argmax(axis=1), average='macro')\n\n    # Plot ROC-AUC curve\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    for i in range(len(class_names)):\n        fpr[i], tpr[i], _ = roc_curve(true_labels == i, predicted_probabilities[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    # Plot ROC-AUC curve\n    fig_roc = go.Figure()\n    for i in range(len(class_names)):\n        fig_roc.add_trace(go.Scatter(x=fpr[i], y=tpr[i], mode='lines', name=f'{class_names[i]} (AUC = {roc_auc[i]:0.2f})'))\n    fig_roc.update_layout(title='ROC Curve',\n                          xaxis_title='False Positive Rate',\n                          yaxis_title='True Positive Rate',\n                          width=1000,\n                          height=1000)\n    if save_path:\n        fig_roc.write_html(save_path)  # Save the plot to the specified path as HTML\n    fig_roc.show()\n\n    print(f'Accuracy: {accuracy}')\n    print(f'Top-5 Accuracy: {top5_accuracy}')\n    print(f'F1 Score: {f1}')\n    print(f'Precision: {precision}')\n    print(f'Recall: {recall}')\n\n# Predict labels and generate confusion matrix\ndef plot_confusion_matrix_and_metrics(generator, model, class_names, title, save_path=None):\n    # Get true labels and predicted labels\n    true_labels, predicted_labels, predicted_probabilities = get_true_and_predicted(generator, model)\n    # Generate confusion matrix\n    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n    plot_confusion_matrix(conf_matrix, class_names, title, save_path)\n\n    # Calculate metrics and plot ROC-AUC curve\n    calculate_metrics_and_plot_roc(np.array(true_labels), np.array(predicted_probabilities), class_names, title, save_path=None)\n\n# Function to calculate top-k accuracy\ndef top_k_accuracy(true_labels, predicted_probabilities, k=5):\n    top_k_predictions = np.argsort(predicted_probabilities, axis=1)[:, -k:]  # Get top k predictions\n    matches = np.zeros_like(true_labels)\n    for i in range(k):\n        matches += (top_k_predictions[:, i] == true_labels)\n    top_k_accuracy = np.mean(matches)\n    return top_k_accuracy\n\n\nclass_names = [k for k, v in dict(sorted(train_generator.class_indices.items(), key=lambda item: item[1])).items()]\n\n# Call above plot and metrics functions\nplot_confusion_matrix_and_metrics(train_generator, model, class_names, 'Confusion Matrix - Training Set', save_path=f\"{MODEL_SAVING_PATH}/training_set_plotly.html\")\nplot_confusion_matrix_and_metrics(validation_generator, model, class_names, 'Confusion Matrix - Validation Set', save_path=f\"{MODEL_SAVING_PATH}/validation_set_plotly.html\")","metadata":{"execution":{"iopub.status.busy":"2024-05-09T13:45:18.510819Z","iopub.execute_input":"2024-05-09T13:45:18.511500Z","iopub.status.idle":"2024-05-09T13:48:02.461929Z","shell.execute_reply.started":"2024-05-09T13:45:18.511467Z","shell.execute_reply":"2024-05-09T13:48:02.460997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CPU configuration","metadata":{}},{"cell_type":"code","source":"# import platform\n# import psutil\n# import os\n\n# # Get CPU information using psutil and platform\n# cpu_info = {\n#     \"processor_name\": platform.processor(),  # Retrieve the processor name\n#     \"cpu_count_physical\": psutil.cpu_count(logical=False),\n#     \"cpu_count_logical\": psutil.cpu_count(logical=True),\n#     \"cpu_frequency_min\": psutil.cpu_freq().min,\n#     \"cpu_frequency_max\": psutil.cpu_freq().max,\n#     \"cpu_frequency_current\": psutil.cpu_freq().current\n# }\n\n# # Get RAM information using psutil\n# ram_info = {\n#     \"total_ram\": psutil.virtual_memory().total / (1024 ** 3)  # Convert bytes to GB\n# }\n\n# # Print the information\n# print(\"CPU Information:\")\n# print(f\"Processor name: {cpu_info['processor_name']}\")\n# print(f\"Physical cores: {cpu_info['cpu_count_physical']}\")\n# print(f\"Logical cores: {cpu_info['cpu_count_logical']}\")\n# print(f\"Minimum frequency: {cpu_info['cpu_frequency_min']} MHz\")\n# print(f\"Maximum frequency: {cpu_info['cpu_frequency_max']} MHz\")\n# print(f\"Current frequency: {cpu_info['cpu_frequency_current']} MHz\")\n\n# print(\"\\nRAM Information:\")\n# print(f\"Total RAM: {ram_info['total_ram']:.2f} GB\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T13:36:45.199368Z","iopub.status.idle":"2024-05-09T13:36:45.199902Z","shell.execute_reply.started":"2024-05-09T13:36:45.199518Z","shell.execute_reply":"2024-05-09T13:36:45.199530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}