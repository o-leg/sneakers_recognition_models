{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8375811,"sourceType":"datasetVersion","datasetId":4980137}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Main notebook\n\n\n***In this notebook we trained different models and evaluated them on validation split.***","metadata":{}},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"markdown","source":"## Setup\n\n**Import libraries and setup execution variables(second code cell)**","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nimport plotly.graph_objs as go\n\nfrom keras.models import load_model\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.applications import MobileNetV2, MobileNet, MobileNetV3Small, EfficientNetB0, EfficientNetB1, EfficientNetB3, EfficientNetB4, EfficientNetB7\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nfrom keras.callbacks import ModelCheckpoint\nfrom sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, roc_curve, auc\n\nimport plotly.io as pio","metadata":{"id":"BTvqUlqRnpXr","execution":{"iopub.status.busy":"2024-03-10T21:11:11.006384Z","iopub.execute_input":"2024-03-10T21:11:11.007296Z","iopub.status.idle":"2024-03-10T21:11:29.884426Z","shell.execute_reply.started":"2024-03-10T21:11:11.007240Z","shell.execute_reply":"2024-03-10T21:11:29.883123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Setup pipeline variables","metadata":{"id":"UwzVnTfMrV3e","execution":{"iopub.status.busy":"2024-03-06T13:21:29.243655Z","iopub.execute_input":"2024-03-06T13:21:29.244264Z","iopub.status.idle":"2024-03-06T13:21:29.250988Z","shell.execute_reply.started":"2024-03-06T13:21:29.244231Z","shell.execute_reply":"2024-03-06T13:21:29.249871Z"}}},{"cell_type":"code","source":"SEED = 20\nDRIVE_PATH = \"/kaggle\"\nDATA_DIRECTORY = f\"{DRIVE_PATH}/input/sneakers-recognition-dataset-v22/Sneakers_Recognition_DataSet\"\nSHOW_DATASET_STRUCTURE = False\nSHOW_IMAGE_SHAPE_MEANS = False\nShOW_IMAGE_SHAPE_PLOT = False\nDRAW_CLASS_DISTRIBUTION = False\n\n# IMAGE_SIZE = (300, 300)\n\n# IMAGE_SIZE = (244, 244)\n\n# IMAGE_SIZE = (224, 224)\nIMAGE_SIZE = (240, 240)\nBATCH_SIZE = 32\nEPOCHS = 15\nNUMBER_LAYERS_TO_FREEZE = 0 \nMODEL_CLASS_CALLBACK = EfficientNetB1\nSHOW_NUMBER_OF_LAYERS_IN_BASE_MODEL = True\nSHOW_MODEL_SUMMARY = False\n\nMODEL_SAVING_PATH = f\"{DRIVE_PATH}/working/models/DATA_V2_{MODEL_CLASS_CALLBACK}_{NUMBER_LAYERS_TO_FREEZE}Frozen_{BATCH_SIZE}Batch_{IMAGE_SIZE[0]}x{IMAGE_SIZE[1]}Size_AugV2\"","metadata":{"execution":{"iopub.status.busy":"2024-03-10T21:11:29.886467Z","iopub.execute_input":"2024-03-10T21:11:29.887547Z","iopub.status.idle":"2024-03-10T21:11:29.895582Z","shell.execute_reply.started":"2024-03-10T21:11:29.887505Z","shell.execute_reply":"2024-03-10T21:11:29.894399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data insights","metadata":{}},{"cell_type":"code","source":"def list_directories(root_dir):\n    \"\"\"\n    Recursively lists all directories and subdirectories within the specified directory.\n\n    Args:\n    - root_dir (str): The directory to list.\n\n    Returns:\n    - directories (list): A list of directory paths.\n    \"\"\"\n    directories = []\n    for dirpath, dirnames, filenames in os.walk(root_dir):\n        directories.append(dirpath)\n        for dirname in dirnames:\n            directories.append(os.path.join(dirpath, dirname))\n    return directories\n\n\nif SHOW_DATASET_STRUCTURE:\n    directories_structure = list_directories(DATA_DIRECTORY)\n    for directory in directories_structure:\n        print(directory)\n","metadata":{"id":"P5iOB85MiSHc","execution":{"iopub.status.busy":"2024-03-10T21:11:29.902037Z","iopub.execute_input":"2024-03-10T21:11:29.902435Z","iopub.status.idle":"2024-03-10T21:11:29.969705Z","shell.execute_reply.started":"2024-03-10T21:11:29.902393Z","shell.execute_reply":"2024-03-10T21:11:29.968187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to calculate mean dimensions of images in a directory\ndef calculate_mean_dimensions(directory):\n    total_width = 0\n    total_height = 0\n    total_images = 0\n\n    # Iterate through files in the directory\n    for filename in os.listdir(directory):\n        if filename.endswith(\".jpg\") or filename.endswith(\".png\"): # Add other formats if needed\n            img_path = os.path.join(directory, filename)\n            img = cv2.imread(img_path)\n            if img is not None:\n                total_width += img.shape[1]\n                total_height += img.shape[0]\n                total_images += 1\n\n    # Calculate mean dimensions\n    if total_images > 0:\n        mean_width = total_width / total_images\n        mean_height = total_height / total_images\n        return mean_width, mean_height\n    else:\n        return 0, 0\n\nif SHOW_IMAGE_SHAPE_MEANS:\n    # Iterate through subdirectories\n    for subdir in os.listdir(DATA_DIRECTORY):\n        subdir_path = os.path.join(DATA_DIRECTORY, subdir)\n        if os.path.isdir(subdir_path):\n            mean_width, mean_height = calculate_mean_dimensions(subdir_path)\n            print(f\"Directory: {subdir}, Mean Width: {mean_width}, Mean Height: {mean_height}\")\n","metadata":{"id":"zoJ-mrYM9sLN","execution":{"iopub.status.busy":"2024-03-10T21:11:29.972234Z","iopub.execute_input":"2024-03-10T21:11:29.973382Z","iopub.status.idle":"2024-03-10T21:11:29.985239Z","shell.execute_reply.started":"2024-03-10T21:11:29.973343Z","shell.execute_reply":"2024-03-10T21:11:29.984047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def collect_dimensions(directory):\n    widths = []\n    heights = []\n\n    # Iterate through files in the directory\n    for root, _, files in os.walk(directory):\n        print(f\"Gathering data from {root} directory\")\n        for filename in files:\n            if filename.endswith(\".jpg\") or filename.endswith(\".png\"): # Add other formats if needed\n                img_path = os.path.join(root, filename)\n                img = cv2.imread(img_path)\n                if img is not None:\n                    widths.append(img.shape[1])\n                    heights.append(img.shape[0])\n\n    return widths, heights\n\ndef plot_dimension_distribution(widths, heights):\n    # Create histograms\n    width_hist = go.Histogram(x=widths, name='Width', marker_color='blue')\n    height_hist = go.Histogram(x=heights, name='Height', marker_color='green')\n\n    # Create figure\n    fig = go.Figure(data=[width_hist, height_hist])\n\n    # Update layout\n    fig.update_layout(\n        title='Image Dimension Distribution',\n        xaxis=dict(title='Dimension'),\n        yaxis=dict(title='Frequency'),\n        barmode='overlay',\n        bargap=0.1\n    )\n\n    # Show plot\n    fig.show()\n\ndef visualize_distribution(directory):\n    widths, heights = collect_dimensions(directory)\n    plot_dimension_distribution(widths, heights)\n\n\nif ShOW_IMAGE_SHAPE_PLOT:\n  # Visualize distribution\n  visualize_distribution(DATA_DIRECTORY)\n","metadata":{"id":"XukpOdIfGcHu","execution":{"iopub.status.busy":"2024-03-10T21:11:29.987506Z","iopub.execute_input":"2024-03-10T21:11:29.988226Z","iopub.status.idle":"2024-03-10T21:11:30.005954Z","shell.execute_reply.started":"2024-03-10T21:11:29.988188Z","shell.execute_reply":"2024-03-10T21:11:30.004558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create train and validation data generators\ntrain_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.2,\n    rotation_range = 30,\n    shear_range = 0.2,\n    height_shift_range = 0.2,\n    width_shift_range = 0.2,\n    brightness_range = (0.2, 1.0),\n    zoom_range = 0.2,\n    horizontal_flip = True,\n    fill_mode = 'nearest'\n)\n\ntrain_generator = train_datagen.flow_from_directory(\n    DATA_DIRECTORY,\n    target_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='training',  # specify this as training data\n    seed=SEED,\n)\n\nvalidation_generator = train_datagen.flow_from_directory(\n    DATA_DIRECTORY,\n    target_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='validation',  # specify this as validation data\n    seed=SEED,\n)\n\nall_labels = set(train_generator.labels).union(validation_generator.labels)\nnumber_of_labels = len(all_labels)","metadata":{"id":"qllRXxP9i0Lk","outputId":"2b7d44b4-11d1-4de8-f6d9-562d1061edf2","execution":{"iopub.status.busy":"2024-03-10T21:11:30.007897Z","iopub.execute_input":"2024-03-10T21:11:30.008372Z","iopub.status.idle":"2024-03-10T21:11:30.506369Z","shell.execute_reply.started":"2024-03-10T21:11:30.008333Z","shell.execute_reply":"2024-03-10T21:11:30.505355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def draw_class_distribution_bar_plot(class_distribution, save_path):\n    sorted_class_distribution = dict(sorted(class_distribution.items()))\n    fig = go.Figure(data=[go.Bar(x=list(sorted_class_distribution.keys()), y=list(sorted_class_distribution.values()))])\n    fig.update_layout(title='Class Distribution',\n                      xaxis_title='Class',\n                      yaxis_title='Count',\n                      width=1000,\n                      height=600)\n    fig.write_html(save_path)  # Save the plot to the specified path as HTML\n    fig.show()\n\n# Example usage of drawing class distribution bar plot\ndef draw_class_distribution(generator, save_path):\n    class_indices_mapping = generator.class_indices\n\n    # Reverse the mapping to get class names from indices\n    class_names = {v: k for k, v in class_indices_mapping.items()}\n    \n    class_distribution = {}\n    for label in generator.labels:\n        if label in class_distribution:\n            class_distribution[label] += 1\n        else:\n            class_distribution[label] = 1\n\n    draw_class_distribution_bar_plot(class_distribution, save_path)\n    \n\nif DRAW_CLASS_DISTRIBUTION:\n    draw_class_distribution(train_generator, os.path.join(f\"{DRIVE_PATH}/working\", \"class_distribution_train.html\"))\n    draw_class_distribution(validation_generator, os.path.join(f\"{DRIVE_PATH}/working\", \"class_distribution_validation.html\"))","metadata":{"execution":{"iopub.status.busy":"2024-03-10T21:11:30.508538Z","iopub.execute_input":"2024-03-10T21:11:30.509518Z","iopub.status.idle":"2024-03-10T21:11:30.523202Z","shell.execute_reply.started":"2024-03-10T21:11:30.509466Z","shell.execute_reply":"2024-03-10T21:11:30.521878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model setup and training","metadata":{}},{"cell_type":"code","source":"# Define the input layer with your desired input shape\ninput_layer = Input(shape=(*IMAGE_SIZE, 3))\n\n# Load the EfficientNetB0 model with pre-trained weights, excluding the top layer\nbase_model = MODEL_CLASS_CALLBACK(input_tensor=input_layer, weights='imagenet', include_top=False)","metadata":{"id":"tfHPn1uizipg","outputId":"9b931d06-149e-4702-e5d3-b16965609a74","execution":{"iopub.status.busy":"2024-03-10T21:11:30.524645Z","iopub.execute_input":"2024-03-10T21:11:30.525867Z","iopub.status.idle":"2024-03-10T21:11:35.146612Z","shell.execute_reply.started":"2024-03-10T21:11:30.525817Z","shell.execute_reply":"2024-03-10T21:11:35.145209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count the number of trainable and non-trainable layers\ndef count_trainable_layers(model):\n    trainable_layers = 0\n    non_trainable_layers = 0\n\n    for layer in model.layers:\n        if layer.trainable:\n            trainable_layers += 1\n        else:\n            non_trainable_layers += 1\n\n    return trainable_layers, non_trainable_layers\n\nif SHOW_NUMBER_OF_LAYERS_IN_BASE_MODEL:\n    # Get the number of trainable and non-trainable layers\n    trainable_layers, non_trainable_layers = count_trainable_layers(base_model)\n\n    print(\"Number of trainable layers:\", trainable_layers)\n    print(\"Number of non-trainable layers:\", non_trainable_layers)\n","metadata":{"id":"jCEH6wRZzgaK","outputId":"8815431d-7305-44d6-d50e-859b3c82c92a","execution":{"iopub.status.busy":"2024-03-10T21:11:35.151675Z","iopub.execute_input":"2024-03-10T21:11:35.153166Z","iopub.status.idle":"2024-03-10T21:11:35.163910Z","shell.execute_reply.started":"2024-03-10T21:11:35.153102Z","shell.execute_reply":"2024-03-10T21:11:35.162442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if SHOW_MODEL_SUMMARY:\n    base_model.summary()","metadata":{"id":"2B9Av6KBvehm","outputId":"e5917b6a-3fb3-4e4c-e3b1-c14a1bee2a33","execution":{"iopub.status.busy":"2024-03-10T21:11:35.165713Z","iopub.execute_input":"2024-03-10T21:11:35.166149Z","iopub.status.idle":"2024-03-10T21:11:35.190851Z","shell.execute_reply.started":"2024-03-10T21:11:35.166117Z","shell.execute_reply":"2024-03-10T21:11:35.189632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model():\n    base_model = MODEL_CLASS_CALLBACK(input_tensor=input_layer, weights='imagenet', include_top=False)\n    # # Freeze layers\n    for layer in base_model.layers[:NUMBER_LAYERS_TO_FREEZE]:\n        layer.trainable = False\n    \n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    predictions = Dense(number_of_labels, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=predictions)\n    return model\n\nmodel = create_model()\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-03-10T21:11:35.192578Z","iopub.execute_input":"2024-03-10T21:11:35.192975Z","iopub.status.idle":"2024-03-10T21:11:37.232862Z","shell.execute_reply.started":"2024-03-10T21:11:35.192945Z","shell.execute_reply":"2024-03-10T21:11:37.231223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import LearningRateScheduler\n\n# Define the learning rate schedule function\ndef lr_schedule(epoch):\n    initial_lr = 0.001\n    if epoch is set([15, 25]):\n        return initial_lr * 0.1\n    return initial_lr\n\n# Define the LearningRateScheduler callback\nlr_scheduler = LearningRateScheduler(lr_schedule)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T21:11:37.234792Z","iopub.execute_input":"2024-03-10T21:11:37.236024Z","iopub.status.idle":"2024-03-10T21:11:37.243410Z","shell.execute_reply.started":"2024-03-10T21:11:37.235967Z","shell.execute_reply":"2024-03-10T21:11:37.241906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ensure the directory exists\nos.makedirs(MODEL_SAVING_PATH, exist_ok=True)\n\n# Define a callback to save the model weights after every epoch\ncheckpoint_filepath = MODEL_SAVING_PATH + \"/model_weights_epoch_{epoch:02d}.weights.h5\"\nmodel_checkpoint_callback = ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    monitor='val_accuracy',\n    mode='max',\n    save_best_only=False,\n    verbose=1\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T21:11:37.245345Z","iopub.execute_input":"2024-03-10T21:11:37.246179Z","iopub.status.idle":"2024-03-10T21:11:37.257927Z","shell.execute_reply.started":"2024-03-10T21:11:37.246144Z","shell.execute_reply":"2024-03-10T21:11:37.256930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train our model","metadata":{}},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(\n    train_generator,\n    validation_data=validation_generator,\n    epochs=EPOCHS,\n    callbacks=[model_checkpoint_callback, lr_scheduler]\n)","metadata":{"id":"MJYKFVTOjXQ-","outputId":"cad35a00-161e-4ab9-b7ca-02579bd59694","execution":{"iopub.status.busy":"2024-03-10T21:11:37.259859Z","iopub.execute_input":"2024-03-10T21:11:37.260338Z","iopub.status.idle":"2024-03-11T01:24:49.586424Z","shell.execute_reply.started":"2024-03-10T21:11:37.260297Z","shell.execute_reply":"2024-03-11T01:24:49.584948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the trained model\n# model.save(f\"{MODEL_SAVING_PATH}/model.keras\") # Previously we used this line, but it did not work well\n\n# TODO: find out why it(above) happens\nmodel.save(f\"{MODEL_SAVING_PATH}/model.h5\") # so not we use this format to store models\n\n","metadata":{"id":"p4wYg_srWb4p","execution":{"iopub.status.busy":"2024-03-11T01:24:49.589252Z","iopub.execute_input":"2024-03-11T01:24:49.590252Z","iopub.status.idle":"2024-03-11T01:24:50.732791Z","shell.execute_reply.started":"2024-03-11T01:24:49.590214Z","shell.execute_reply":"2024-03-11T01:24:50.731280Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate on validation set","metadata":{}},{"cell_type":"code","source":"# Get training and validation loss values\ntrain_loss = history.history['loss']\nval_loss = history.history['val_loss']\n\n# Get training and validation accuracy values\ntrain_acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\n# Create traces for loss\nloss_trace = go.Scatter(x=list(range(1, len(train_loss) + 1)), y=train_loss, mode='lines', name='Training Loss')\nval_loss_trace = go.Scatter(x=list(range(1, len(val_loss) + 1)), y=val_loss, mode='lines', name='Validation Loss')\n\n# Create traces for accuracy\nacc_trace = go.Scatter(x=list(range(1, len(train_acc) + 1)), y=train_acc, mode='lines', name='Training Accuracy')\nval_acc_trace = go.Scatter(x=list(range(1, len(val_acc) + 1)), y=val_acc, mode='lines', name='Validation Accuracy')\n\n# Create figure for loss\nloss_fig = go.Figure(data=[loss_trace, val_loss_trace])\nloss_fig.update_layout(title='Training and Validation Loss',\n                       xaxis_title='Epoch',\n                       yaxis_title='Loss')\n\n# Create figure for accuracy\nacc_fig = go.Figure(data=[acc_trace, val_acc_trace])\nacc_fig.update_layout(title='Training and Validation Accuracy',\n                      xaxis_title='Epoch',\n                      yaxis_title='Accuracy')\n\n# Save figures as HTML files\npio.write_html(loss_fig, f\"{MODEL_SAVING_PATH}/loss_figure.html\")\npio.write_html(acc_fig, f\"{MODEL_SAVING_PATH}/accuracy_figure.html\")\n","metadata":{"id":"yNehpeTczZsl","execution":{"iopub.status.busy":"2024-03-11T01:24:50.734849Z","iopub.execute_input":"2024-03-11T01:24:50.735340Z","iopub.status.idle":"2024-03-11T01:24:51.119874Z","shell.execute_reply.started":"2024-03-11T01:24:50.735299Z","shell.execute_reply":"2024-03-11T01:24:51.118818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_true_and_predicted(generator, model):\n    # Get true labels and predicted labels\n    true_labels = []\n    predicted_labels = []\n    predicted_probabilities = []\n    for i in range(len(generator)):\n        batch = generator[i]\n        true_labels.extend(np.argmax(batch[1], axis=1))  # Extract true labels from the batch\n        predictions = model.predict(batch[0])\n        predicted_labels.extend(np.argmax(predictions, axis=1))  # Extract predicted labels\n        predicted_probabilities.extend(predictions)  # Extract predicted probabilities\n    return true_labels, predicted_labels, predicted_probabilities","metadata":{"execution":{"iopub.status.busy":"2024-03-11T01:24:51.121473Z","iopub.execute_input":"2024-03-11T01:24:51.121939Z","iopub.status.idle":"2024-03-11T01:24:51.130873Z","shell.execute_reply.started":"2024-03-11T01:24:51.121897Z","shell.execute_reply":"2024-03-11T01:24:51.129731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Function to plot confusion matrix using Plotly\ndef plot_confusion_matrix(conf_matrix, class_names, title, save_path=None):\n    trace = go.Heatmap(z=np.flipud(conf_matrix),  # Reverse the y-axis\n                       x=class_names,\n                       y=class_names[::-1],  # Reverse the y-axis labels\n                       colorscale='Blues',\n                       colorbar=dict(title='Count'),\n                       )\n    layout = go.Layout(title=title,\n                       xaxis=dict(title='Predicted labels'),\n                       yaxis=dict(title='True labels'),\n                       width=1000,  # Specify width of the plot\n                       height=1000,  # Specify height of the plot\n#                        legend=dict(title='Legend'),  # Include legend\n                       )\n    fig = go.Figure(data=[trace], layout=layout)\n    if save_path:\n        fig.write_html(save_path)  # Save the plot to the specified path as HTML\n    fig.show()\n\n# Function to calculate metrics and plot ROC-AUC curve\ndef calculate_metrics_and_plot_roc(true_labels, predicted_probabilities, class_names, title, save_path=None):\n    # Calculate accuracy\n    accuracy = accuracy_score(true_labels, predicted_probabilities.argmax(axis=1))\n\n    # Calculate top-5 accuracy\n    top5_accuracy = top_k_accuracy(true_labels, predicted_probabilities, k=5)\n\n    # Calculate F1 score\n    f1 = f1_score(true_labels, predicted_probabilities.argmax(axis=1), average='macro')\n\n    # Calculate precision\n    precision = precision_score(true_labels, predicted_probabilities.argmax(axis=1), average='macro')\n\n    # Calculate recall\n    recall = recall_score(true_labels, predicted_probabilities.argmax(axis=1), average='macro')\n\n    # Plot ROC-AUC curve\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    for i in range(len(class_names)):\n        fpr[i], tpr[i], _ = roc_curve(true_labels == i, predicted_probabilities[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    # Plot ROC-AUC curve\n    fig_roc = go.Figure()\n    for i in range(len(class_names)):\n        fig_roc.add_trace(go.Scatter(x=fpr[i], y=tpr[i], mode='lines', name=f'{class_names[i]} (AUC = {roc_auc[i]:0.2f})'))\n    fig_roc.update_layout(title='ROC Curve',\n                          xaxis_title='False Positive Rate',\n                          yaxis_title='True Positive Rate',\n                          width=1000,\n                          height=1000)\n    if save_path:\n        fig_roc.write_html(save_path)  # Save the plot to the specified path as HTML\n    fig_roc.show()\n\n    print(f'Accuracy: {accuracy}')\n    print(f'Top-5 Accuracy: {top5_accuracy}')\n    print(f'F1 Score: {f1}')\n    print(f'Precision: {precision}')\n    print(f'Recall: {recall}')\n\n# Predict labels and generate confusion matrix\ndef plot_confusion_matrix_and_metrics(generator, model, class_names, title, save_path=None):\n    # Get true labels and predicted labels\n    true_labels, predicted_labels, predicted_probabilities = get_true_and_predicted(generator, model)\n    # Generate confusion matrix\n    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n    plot_confusion_matrix(conf_matrix, class_names, title, save_path)\n\n    # Calculate metrics and plot ROC-AUC curve\n    calculate_metrics_and_plot_roc(np.array(true_labels), np.array(predicted_probabilities), class_names, title, save_path=None)\n\n# Function to calculate top-k accuracy\ndef top_k_accuracy(true_labels, predicted_probabilities, k=5):\n    top_k_predictions = np.argsort(predicted_probabilities, axis=1)[:, -k:]  # Get top k predictions\n    matches = np.zeros_like(true_labels)\n    for i in range(k):\n        matches += (top_k_predictions[:, i] == true_labels)\n    top_k_accuracy = np.mean(matches)\n    return top_k_accuracy\n\n\nclass_names = [k for k, v in dict(sorted(train_generator.class_indices.items(), key=lambda item: item[1])).items()]\n\n# Call above plot and metrics functions\nplot_confusion_matrix_and_metrics(train_generator, model, class_names, 'Confusion Matrix - Training Set', save_path=f\"{MODEL_SAVING_PATH}/training_set_plotly.html\")\nplot_confusion_matrix_and_metrics(validation_generator, model, class_names, 'Confusion Matrix - Validation Set', save_path=f\"{MODEL_SAVING_PATH}/validation_set_plotly.html\")","metadata":{"execution":{"iopub.status.busy":"2024-03-11T01:24:51.132697Z","iopub.execute_input":"2024-03-11T01:24:51.133093Z","iopub.status.idle":"2024-03-11T01:31:51.801279Z","shell.execute_reply.started":"2024-03-11T01:24:51.133061Z","shell.execute_reply":"2024-03-11T01:31:51.799938Z"},"trusted":true},"execution_count":null,"outputs":[]}]}